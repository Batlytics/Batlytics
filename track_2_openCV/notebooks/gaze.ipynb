{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "8d3bea27-36b8-4832-b61f-9af40feef9fd",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d9ece0f1",
    "execution_start": 1645312372013,
    "execution_millis": 1627,
    "deepnote_cell_type": "code"
   },
   "source": "import cv2\nimport time\nimport numpy as np\nimport pandas as pd\nimport mediapipe as mp\nimport plotly.express as px\nimport plotly.graph_objects as go",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Pose Detection + Gaze",
   "metadata": {
    "cell_id": "5fa54231-2f09-4b56-9bb4-0803b540a2c6",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "998502ab-0da7-45cf-b0fa-ba0b49148e16",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9a6d5a35",
    "execution_start": 1645312375017,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "ANGLE_BGR_COLOR = (0,165,255)\nPOSE_BGR_COLOR = (255,0,0)\nFPS_BGR_COLOR = (0,0,255)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "45eef9c3-034e-4d74-ac51-5d7278c4a8a6",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "864c06c7",
    "execution_start": 1645313149704,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "class poseDetector:\n    def __init__(\n        self,\n        mode=False,\n        complex=1,\n        smooth_landmarks=True,\n        segmentation=True,\n        smooth_segmentation=True,\n        detectionCon=0.5,\n        trackCon=0.5,\n    ):\n\n        self.mode = mode\n        self.complex = complex\n        self.smooth_landmarks = smooth_landmarks\n        self.segmentation = segmentation\n        self.smooth_segmentation = smooth_segmentation\n        self.detectionCon = detectionCon\n        self.trackCon = trackCon\n\n        self.mpDraw = mp.solutions.drawing_utils\n        self.mpDrawStyle = mp.solutions.drawing_styles\n        self.mpPose = mp.solutions.pose\n        self.pose = self.mpPose.Pose(\n            self.mode,\n            self.complex,\n            self.smooth_landmarks,\n            self.segmentation,\n            self.smooth_segmentation,\n            self.detectionCon,\n            self.trackCon,\n        )\n        self.mp_drawing = mp.solutions.drawing_utils\n\n    def findPose(self, img, draw = True):\n        '''\n        Pose estimation and drawing of the pose estimation to given frame.\n        '''\n        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        self.results = self.pose.process(imgRGB)    \n        # self.plotly_fig(self.results.pose_landmarks)   \n        # print(self.results.pose_landmarks)\n          \n        # Code to capture all body points and map it to a video\n        if self.results.pose_landmarks:\n            if draw:\n                self.mp_drawing.draw_landmarks(\n                    img,\n                    self.results.pose_landmarks,\n                    self.mpPose.POSE_CONNECTIONS,\n                    self.mpDrawStyle.get_default_pose_landmarks_style())\n                    # self.mpDraw.DrawingSpec(\n                    #     color=(0, 0, 255), thickness=2, circle_radius=2\n                    # ),\n                    # self.mpDraw.DrawingSpec(\n                    #     color=(0, 255, 0), thickness=2, circle_radius=2\n                    # ),\n        return img\n\n    def findPosition(self, img, draw=False):\n        '''\n        Finds position of all the landmarks from previous pose estimation.\n        '''\n        self.lmList = []\n        if self.results.pose_landmarks:\n            # Save landmarks\n            for id, lm in enumerate(self.results.pose_landmarks.landmark):\n                h, w, c = img.shape\n                # print(id, lm)\n                cx, cy = int(lm.x * w), int(lm.y * h)\n                x, y, z = lm.x, lm.y, lm.z\n                self.lmList.append([id, cx, cy])\n                if draw:\n                    cv2.circle(img, (cx, cy), 5, (0, 255, 0), cv2.FILLED)\n        return self.lmList\n\n    def findAngle(self, img, p1, p2, p3, draw=True):\n        # Get the landmarks\n        x1, y1 = self.lmList[p1][1:]\n        x2, y2 = self.lmList[p2][1:]\n        x3, y3 = self.lmList[p3][1:]\n\n        # Calculate the Angle\n        radians = np.arctan2(y3 - y2, x3 - x2) - np.arctan2(y1 - y2, x1 - x2)\n        angle = radians * 180.0 / np.pi # np.abs(radians * 180.0 / np.pi)\n\n        if angle > 180.0:\n            angle = -(360 - angle)\n        elif angle < -180:\n            angle += 360\n\n        # print(int(angle))\n\n        # Draw\n        if draw:\n            # cv2.line(img, (x1, y1), (x2, y2), (255, 255, 255), 3)\n            # cv2.line(img, (x3, y3), (x2, y2), (255, 255, 255), 3)\n            # cv2.circle(img, (x1, y1), 5, (0, 0, 255), cv2.FILLED)\n            # cv2.circle(img, (x1, y1), 10, (0, 0, 255), 2)\n            # cv2.circle(img, (x2, y2), 5, (0, 0, 255), cv2.FILLED)\n            # cv2.circle(img, (x2, y2), 10, (0, 0, 255), 2)\n            # cv2.circle(img, (x3, y3), 5, (0, 0, 255), cv2.FILLED)\n            # cv2.circle(img, (x3, y3), 10, (0, 0, 255), 2)\n            cv2.putText(\n                img,\n                str(int(angle)) + \"\",\n                (x2 - 50, y2 + 50),\n                cv2.FONT_HERSHEY_PLAIN,\n                2,\n                ANGLE_BGR_COLOR,# (255, 0, 0),\n                2,\n            )\n        return angle",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "5dbc1e06-6daf-4a74-8a90-a3507ff72a40",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "11a4c6c7",
    "execution_start": 1645312386677,
    "execution_millis": 648,
    "deepnote_cell_type": "code"
   },
   "source": "OUTPUT_DIR = 'out'\nVIDEO_OUT_PATH = 'out.mp4'\n!mkdir out",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "mkdir: cannot create directory ‘out’: File exists\r\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "c5d73c72-39a9-4507-ad6f-3b4dcbf72e75",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "648e7026",
    "execution_start": 1645316135246,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "size = (1920, 1080)\nfourcc = cv2.VideoWriter_fourcc(*'MP4V') # cv2.VideoWriter_fourcc(*'DIVX') \nFPS = 25\nout = cv2.VideoWriter(VIDEO_OUT_PATH,fourcc,FPS, size)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "0e559ed6-0d72-4e56-af94-936870747d8c",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "42c3ca8b",
    "execution_start": 1645316135786,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "GAZE_LINE_THICNKESS = 1\nGAZE_LINE_COLOR = (0,0,255)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "cecbcd1c-7833-47c1-aa8b-ce8478dfaac6",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "60482ead",
    "execution_start": 1645316136664,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "def gaze(img, detector):\n    left_eye_coordinates = detector.lmList[2][1:]\n    right_eye_coordinates = detector.lmList[5][1:]\n    \n    mid_eye_point = (int((left_eye_coordinates[0] + right_eye_coordinates[0]) / 2), \n                     int((left_eye_coordinates[1] + right_eye_coordinates[1]) / 2))\n    nose_point = detector.lmList[0][1:]\n\n    theta = np.arctan2(mid_eye_point[1] - nose_point[1], mid_eye_point[0] - nose_point[0])\n    endpt_x = int(mid_eye_point[0] - 1000*np.cos(theta))\n    endpt_y = int(mid_eye_point[1] - 1000*np.sin(theta))\n\n    # Mid eye point -> nose line\n    return cv2.line(img, mid_eye_point, (endpt_x, endpt_y), GAZE_LINE_COLOR, GAZE_LINE_THICNKESS)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "773ca73d-6bf6-4234-a3fd-1e7330944f7e",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "95a2204d",
    "execution_start": 1645316138432,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "def main():\n    cap = cv2.VideoCapture('Hackathon_1st_Hitter.mp4')\n    milliseconds = 1000\n    start_time = int(input(\"Enter Start time (in seconds): \"))\n    end_time = int(input(\"Enter Length (in seconds): \"))\n    end_time = start_time + end_time\n    cap.set(cv2.CAP_PROP_POS_MSEC, start_time * milliseconds)\n    # pTime = 0\n    detector = poseDetector()\n    cnt = 0\n    while True and cap.get(cv2.CAP_PROP_POS_MSEC) <= end_time * milliseconds:\n    # success = True\n    # while success:\n        success, img = cap.read()\n\n        # Pose estimation + pose drawing\n        img = detector.findPose(img, draw=True)\n        lmList = detector.findPosition(img, draw=False)#, #draw=True)\n\n        if len(lmList) != 0:\n            detector.findAngle(img, 13, 11, 23)\n            detector.findAngle(img, 24, 12, 14)\n        \n        # Gaze + drawing\n        if detector.lmList:\n            img = gaze(img, detector)\n\n        # Save output image\n        # cv2.imwrite(\"{}/image_{}.jpg\".format(OUTPUT_DIR, cnt), img)\n        \n        # Output frame to the video\n        out.write(img)\n\n        cnt += 1\n        # if cnt >= 3:\n        #     break\n\n    out.release()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "69bc5d1a-43ad-464b-afa1-9a0aae30b05b",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "286a4539",
    "execution_start": 1645316139402,
    "execution_millis": 40145,
    "deepnote_cell_type": "code"
   },
   "source": "main()",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "f734eeb5-7c78-429a-a35d-57252ada9a57",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "53ac9a58",
    "execution_start": 1645313107276,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "# x = [[0, 885, 191, 0.9997202157974243], [1, 879, 176, 0.9997184872627258], [2, 874, 175, 0.9997063279151917], [3, 870, 174, 0.9996131658554077], [4, 890, 177, 0.9997570514678955], [5, 893, 177, 0.9997616410255432], [6, 896, 176, 0.99972003698349], [7, 864, 181, 0.9994305968284607], [8, 900, 182, 0.9997619986534119], [9, 878, 201, 0.999589204788208], [10, 890, 202, 0.9996969103813171], [11, 801, 268, 0.9998000264167786], [12, 957, 260, 0.9999763369560242], [13, 767, 377, 0.9374921321868896], [14, 1021, 382, 0.9838160276412964], [15, 770, 421, 0.6886430978775024], [16, 1001, 464, 0.665144681930542], [17, 757, 431, 0.582179069519043], [18, 999, 494, 0.5551601648330688], [19, 769, 427, 0.572348952293396], [20, 993, 491, 0.5417897701263428], [21, 772, 420, 0.49530112743377686], [22, 982, 474, 0.48708102107048035], [23, 839, 483, 0.9997233748435974], [24, 908, 492, 0.9999595880508423], [25, 885, 607, 0.7366760969161987], [26, 886, 659, 0.9951562881469727], [27, 925, 731, 0.920708954334259], [28, 850, 846, 0.9939728379249573], [29, 935, 757, 0.9209998846054077], [30, 828, 879, 0.9771071076393127], [31, 966, 739, 0.8682690858840942], [32, 911, 864, 0.9716724753379822]]\n# sorted(x, key=lambda x: x[3])[:10]",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "08ada81d-11e8-41ea-97c6-d508de99218b",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4873503b",
    "execution_start": 1645306386929,
    "execution_millis": 207,
    "deepnote_cell_type": "code"
   },
   "source": "import multiprocessing\n\nmultiprocessing.cpu_count()\n\n# TODO - multithread processing for Mediapipe Pose and batch processing for YOLOv5",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 53,
     "data": {
      "text/plain": "4"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=380d27e3-c5ba-4379-bcc3-a75537d76331' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "e3ae50f5-af2e-4e80-b24d-b6a56f71d2ff",
  "deepnote_execution_queue": []
 }
}